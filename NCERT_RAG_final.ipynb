{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thekabi-4/NCERT_SLM_RAG/blob/main/NCERT_RAG_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Clone llama.cpp"
      ],
      "metadata": {
        "id": "qhrGu22s7bDB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0OUUjsAb7TBe",
        "outputId": "56ce0260-69c2-4f50-c413-87a6eafa480a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 57507, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 57507 (delta 54), reused 21 (delta 21), pack-reused 57425 (from 3)\u001b[K\n",
            "Receiving objects: 100% (57507/57507), 136.44 MiB | 33.33 MiB/s, done.\n",
            "Resolving deltas: 100% (41682/41682), done.\n",
            "/content/models/llama.cpp\n",
            "mkdir: cannot create directory ‘models’: File exists\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp.git\n",
        "%cd llama.cpp\n",
        "!mkdir models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 2: Install dependencies"
      ],
      "metadata": {
        "id": "egHl7I7V7g_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y cmake build-essential\n",
        "!pip install --upgrade pip\n",
        "!pip install faiss-cpu symspellpy transformers sentencepiece\n",
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Fqh-WzC27Yu7",
        "outputId": "2d30cded-c907-40b3-b778-b1c0246f5ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0.post1)\n",
            "Requirement already satisfied: symspellpy in /usr/local/lib/python3.11/dist-packages (6.9.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: editdistpy>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from symspellpy) (0.1.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.0.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Build llama.cpp with CPU (or Metal/GPU later)"
      ],
      "metadata": {
        "id": "pJanHjnn7x-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p models\n",
        "!wget -O models/tinyllama.gguf https://huggingface.co/TheBloke/TinyLLaMA-1.1B-Chat-v0.3-GGUF/resolve/main/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goAjg1ozD46b",
        "outputId": "224c95e3-c0df-403e-d24f-225fedbb852c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-28 03:26:22--  https://huggingface.co/TheBloke/TinyLLaMA-1.1B-Chat-v0.3-GGUF/resolve/main/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.124, 18.172.134.88, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF/resolve/main/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf [following]\n",
            "--2025-07-28 03:26:22--  https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF/resolve/main/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/65/bb/65bb2b45ed3e7c59378b71dc526f1f5a568b37d1354b0f80871ac18c114af42b/2d3bd82534bb6c6e0f4be1761b29b25bdcd65855a022513cb65f24ad3b25e41f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf%3B+filename%3D%22tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf%22%3B&Expires=1753676782&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MzY3Njc4Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82NS9iYi82NWJiMmI0NWVkM2U3YzU5Mzc4YjcxZGM1MjZmMWY1YTU2OGIzN2QxMzU0YjBmODA4NzFhYzE4YzExNGFmNDJiLzJkM2JkODI1MzRiYjZjNmUwZjRiZTE3NjFiMjliMjViZGNkNjU4NTVhMDIyNTEzY2I2NWYyNGFkM2IyNWU0MWY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=OSzIF4xAsy9%7E9TH0gB3civDwOpvo7jWPtreX-TL7dvR3a7KGKlsQq9J9JbF-NbkuFSfkrVNpkPr9Tlz694dONfHQfWTCRINso8tFlJRu1qbABe9Cq%7EjqBYsvLci8LGuqYktfrD9YNPyTle8TmYpXPH08qC5fhTzYB9PyjKHAUlzVMSItq3NOST92bORfFD%7EwI6Qv56U7Ux4%7EhblowFHrEKMFONRhxUi0d04TXMFxB0273mWGKLvL2dqLyxnHWn5pM3NFA2GVl-17zfNn1vPhQ1piZXZWEF6h91ErpXFkrgCJIchWpFyjMYI8YH-fdomC6zi0eqP-tox8U-yf1rTJNQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-07-28 03:26:22--  https://cdn-lfs.hf.co/repos/65/bb/65bb2b45ed3e7c59378b71dc526f1f5a568b37d1354b0f80871ac18c114af42b/2d3bd82534bb6c6e0f4be1761b29b25bdcd65855a022513cb65f24ad3b25e41f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf%3B+filename%3D%22tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf%22%3B&Expires=1753676782&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MzY3Njc4Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82NS9iYi82NWJiMmI0NWVkM2U3YzU5Mzc4YjcxZGM1MjZmMWY1YTU2OGIzN2QxMzU0YjBmODA4NzFhYzE4YzExNGFmNDJiLzJkM2JkODI1MzRiYjZjNmUwZjRiZTE3NjFiMjliMjViZGNkNjU4NTVhMDIyNTEzY2I2NWYyNGFkM2IyNWU0MWY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=OSzIF4xAsy9%7E9TH0gB3civDwOpvo7jWPtreX-TL7dvR3a7KGKlsQq9J9JbF-NbkuFSfkrVNpkPr9Tlz694dONfHQfWTCRINso8tFlJRu1qbABe9Cq%7EjqBYsvLci8LGuqYktfrD9YNPyTle8TmYpXPH08qC5fhTzYB9PyjKHAUlzVMSItq3NOST92bORfFD%7EwI6Qv56U7Ux4%7EhblowFHrEKMFONRhxUi0d04TXMFxB0273mWGKLvL2dqLyxnHWn5pM3NFA2GVl-17zfNn1vPhQ1piZXZWEF6h91ErpXFkrgCJIchWpFyjMYI8YH-fdomC6zi0eqP-tox8U-yf1rTJNQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.167.152.106, 3.167.152.37, 3.167.152.12, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.167.152.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 667822976 (637M) [binary/octet-stream]\n",
            "Saving to: ‘models/tinyllama.gguf’\n",
            "\n",
            "models/tinyllama.gg 100%[===================>] 636.88M   259MB/s    in 2.5s    \n",
            "\n",
            "2025-07-28 03:26:25 (259 MB/s) - ‘models/tinyllama.gguf’ saved [667822976/667822976]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cmake -B build\n",
        "!cmake --build build --config Release"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5I8DlpuN705n",
        "outputId": "d0508a25-df26-49f4-c601-b31a8585ff92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\") \n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE  \n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- GGML_SYSTEM_ARCH: x86\n",
            "-- Including CPU backend\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- ggml version: 0.0.6006\n",
            "-- ggml commit:  7f975995\n",
            "-- Found CURL: /usr/lib/x86_64-linux-gnu/libcurl.so (found version \"7.81.0\")  \n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/models/llama.cpp/build\n",
            "[  1%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-base.so\u001b[0m\n",
            "[  4%] Built target ggml-base\n",
            "[  5%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-cpu.so\u001b[0m\n",
            "[ 11%] Built target ggml-cpu\n",
            "[ 11%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml.so\u001b[0m\n",
            "[ 11%] Built target ggml\n",
            "[ 11%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-cparams.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache-unified.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache-unified-iswa.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-saver.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32m\u001b[1mLinking CXX shared library ../bin/libllama.so\u001b[0m\n",
            "[ 22%] Built target llama\n",
            "[ 22%] \u001b[32mBuilding CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o\u001b[0m\n",
            "[ 22%] Built target build_info\n",
            "[ 22%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/arg.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat-parser.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/console.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-partial.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/llguidance.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/log.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/regex-partial.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/sampling.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/speculative.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32m\u001b[1mLinking CXX static library libcommon.a\u001b[0m\n",
            "[ 28%] Built target common\n",
            "[ 28%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-0\u001b[0m\n",
            "[ 28%] Built target test-tokenizer-0\n",
            "[ 29%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/get-model.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-sampling\u001b[0m\n",
            "[ 29%] Built target test-sampling\n",
            "[ 29%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-grammar-parser\u001b[0m\n",
            "[ 30%] Built target test-grammar-parser\n",
            "[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/get-model.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-grammar-integration\u001b[0m\n",
            "[ 31%] Built target test-grammar-integration\n",
            "[ 31%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o\u001b[0m\n",
            "[ 32%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-llama-grammar\u001b[0m\n",
            "[ 32%] Built target test-llama-grammar\n",
            "[ 32%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/test-chat.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/get-model.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat\u001b[0m\n",
            "[ 33%] Built target test-chat\n",
            "[ 34%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-json-schema-to-grammar\u001b[0m\n",
            "[ 35%] Built target test-json-schema-to-grammar\n",
            "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-stats.dir/test-quantize-stats.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-stats\u001b[0m\n",
            "[ 36%] Built target test-quantize-stats\n",
            "[ 36%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gbnf-validator.dir/test-gbnf-validator.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-gbnf-validator\u001b[0m\n",
            "[ 36%] Built target test-gbnf-validator\n",
            "[ 37%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-1-bpe\u001b[0m\n",
            "[ 37%] Built target test-tokenizer-1-bpe\n",
            "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-1-spm\u001b[0m\n",
            "[ 38%] Built target test-tokenizer-1-spm\n",
            "[ 39%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-parser.dir/test-chat-parser.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-parser.dir/get-model.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat-parser\u001b[0m\n",
            "[ 39%] Built target test-chat-parser\n",
            "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/get-model.cpp.o\u001b[0m\n",
            "[ 41%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat-template\u001b[0m\n",
            "[ 41%] Built target test-chat-template\n",
            "[ 41%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-partial.dir/test-json-partial.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-partial.dir/get-model.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-json-partial\u001b[0m\n",
            "[ 42%] Built target test-json-partial\n",
            "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/test-log.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/get-model.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-log\u001b[0m\n",
            "[ 43%] Built target test-log\n",
            "[ 43%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-regex-partial.dir/test-regex-partial.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-regex-partial.dir/get-model.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-regex-partial\u001b[0m\n",
            "[ 44%] Built target test-regex-partial\n",
            "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-thread-safety.dir/test-thread-safety.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-thread-safety.dir/get-model.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-thread-safety\u001b[0m\n",
            "[ 46%] Built target test-thread-safety\n",
            "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/get-model.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-arg-parser\u001b[0m\n",
            "[ 47%] Built target test-arg-parser\n",
            "[ 48%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/test-gguf.cpp.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/get-model.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-gguf\u001b[0m\n",
            "[ 49%] Built target test-gguf\n",
            "[ 49%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-backend-ops\u001b[0m\n",
            "[ 50%] Built target test-backend-ops\n",
            "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-model-load-cancel\u001b[0m\n",
            "[ 51%] Built target test-model-load-cancel\n",
            "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-autorelease\u001b[0m\n",
            "[ 53%] Built target test-autorelease\n",
            "[ 53%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/test-barrier.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/get-model.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-barrier\u001b[0m\n",
            "[ 54%] Built target test-barrier\n",
            "[ 55%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o\u001b[0m\n",
            "[ 56%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-fns\u001b[0m\n",
            "[ 56%] Built target test-quantize-fns\n",
            "[ 56%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-perf\u001b[0m\n",
            "[ 57%] Built target test-quantize-perf\n",
            "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/test-rope.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/get-model.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-rope\u001b[0m\n",
            "[ 58%] Built target test-rope\n",
            "[ 59%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-audio.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libmtmd.so\u001b[0m\n",
            "[ 60%] Built target mtmd\n",
            "[ 61%] \u001b[32mBuilding C object tests/CMakeFiles/test-mtmd-c-api.dir/test-mtmd-c-api.c.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-mtmd-c-api.dir/get-model.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-mtmd-c-api\u001b[0m\n",
            "[ 61%] Built target test-mtmd-c-api\n",
            "[ 61%] \u001b[32mBuilding C object tests/CMakeFiles/test-c.dir/test-c.c.o\u001b[0m\n",
            "[ 62%] \u001b[32m\u001b[1mLinking C executable ../bin/test-c\u001b[0m\n",
            "[ 62%] Built target test-c\n",
            "[ 62%] \u001b[32mBuilding CXX object examples/batched/CMakeFiles/llama-batched.dir/batched.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-batched\u001b[0m\n",
            "[ 63%] Built target llama-batched\n",
            "[ 63%] \u001b[32mBuilding CXX object examples/embedding/CMakeFiles/llama-embedding.dir/embedding.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-embedding\u001b[0m\n",
            "[ 63%] Built target llama-embedding\n",
            "[ 64%] \u001b[32mBuilding CXX object examples/eval-callback/CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-eval-callback\u001b[0m\n",
            "[ 64%] Built target llama-eval-callback\n",
            "[ 64%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o\u001b[0m\n",
            "[ 64%] Built target sha256\n",
            "[ 65%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o\u001b[0m\n",
            "[ 65%] Built target xxhash\n",
            "[ 66%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o\u001b[0m\n",
            "[ 66%] Built target sha1\n",
            "[ 67%] \u001b[32mBuilding CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o\u001b[0m\n",
            "[ 67%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf-hash\u001b[0m\n",
            "[ 67%] Built target llama-gguf-hash\n",
            "[ 68%] \u001b[32mBuilding CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf\u001b[0m\n",
            "[ 68%] Built target llama-gguf\n",
            "[ 68%] \u001b[32mBuilding CXX object examples/gritlm/CMakeFiles/llama-gritlm.dir/gritlm.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gritlm\u001b[0m\n",
            "[ 69%] Built target llama-gritlm\n",
            "[ 70%] \u001b[32mBuilding CXX object examples/lookahead/CMakeFiles/llama-lookahead.dir/lookahead.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookahead\u001b[0m\n",
            "[ 70%] Built target llama-lookahead\n",
            "[ 71%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup.dir/lookup.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup\u001b[0m\n",
            "[ 71%] Built target llama-lookup\n",
            "[ 71%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-create\u001b[0m\n",
            "[ 72%] Built target llama-lookup-create\n",
            "[ 72%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-merge\u001b[0m\n",
            "[ 73%] Built target llama-lookup-merge\n",
            "[ 73%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-stats\u001b[0m\n",
            "[ 73%] Built target llama-lookup-stats\n",
            "[ 74%] \u001b[32mBuilding CXX object examples/parallel/CMakeFiles/llama-parallel.dir/parallel.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-parallel\u001b[0m\n",
            "[ 74%] Built target llama-parallel\n",
            "[ 74%] \u001b[32mBuilding CXX object examples/passkey/CMakeFiles/llama-passkey.dir/passkey.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-passkey\u001b[0m\n",
            "[ 75%] Built target llama-passkey\n",
            "[ 75%] \u001b[32mBuilding CXX object examples/retrieval/CMakeFiles/llama-retrieval.dir/retrieval.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-retrieval\u001b[0m\n",
            "[ 76%] Built target llama-retrieval\n",
            "[ 76%] \u001b[32mBuilding CXX object examples/save-load-state/CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-save-load-state\u001b[0m\n",
            "[ 77%] Built target llama-save-load-state\n",
            "[ 77%] \u001b[32mBuilding CXX object examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-simple\u001b[0m\n",
            "[ 77%] Built target llama-simple\n",
            "[ 78%] \u001b[32mBuilding CXX object examples/simple-chat/CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-simple-chat\u001b[0m\n",
            "[ 78%] Built target llama-simple-chat\n",
            "[ 79%] \u001b[32mBuilding CXX object examples/speculative/CMakeFiles/llama-speculative.dir/speculative.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-speculative\u001b[0m\n",
            "[ 79%] Built target llama-speculative\n",
            "[ 79%] \u001b[32mBuilding CXX object examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-speculative-simple\u001b[0m\n",
            "[ 80%] Built target llama-speculative-simple\n",
            "[ 80%] \u001b[32mBuilding CXX object examples/gen-docs/CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gen-docs\u001b[0m\n",
            "[ 80%] Built target llama-gen-docs\n",
            "[ 80%] \u001b[32mBuilding CXX object examples/training/CMakeFiles/llama-finetune.dir/finetune.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-finetune\u001b[0m\n",
            "[ 81%] Built target llama-finetune\n",
            "[ 81%] \u001b[32mBuilding CXX object examples/diffusion/CMakeFiles/llama-diffusion-cli.dir/diffusion-cli.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-diffusion-cli\u001b[0m\n",
            "[ 82%] Built target llama-diffusion-cli\n",
            "[ 82%] \u001b[32mBuilding CXX object examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-convert-llama2c-to-ggml\u001b[0m\n",
            "[ 83%] Built target llama-convert-llama2c-to-ggml\n",
            "[ 84%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-vdot.dir/vdot.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-vdot\u001b[0m\n",
            "[ 84%] Built target llama-vdot\n",
            "[ 84%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-q8dot.dir/q8dot.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-q8dot\u001b[0m\n",
            "[ 84%] Built target llama-q8dot\n",
            "[ 84%] \u001b[32mBuilding CXX object tools/batched-bench/CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-batched-bench\u001b[0m\n",
            "[ 84%] Built target llama-batched-bench\n",
            "[ 84%] \u001b[32mBuilding CXX object tools/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf-split\u001b[0m\n",
            "[ 85%] Built target llama-gguf-split\n",
            "[ 85%] \u001b[32mBuilding CXX object tools/imatrix/CMakeFiles/llama-imatrix.dir/imatrix.cpp.o\u001b[0m\n",
            "[ 86%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-imatrix\u001b[0m\n",
            "[ 86%] Built target llama-imatrix\n",
            "[ 87%] \u001b[32mBuilding CXX object tools/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-bench\u001b[0m\n",
            "[ 87%] Built target llama-bench\n",
            "[ 88%] \u001b[32mBuilding CXX object tools/main/CMakeFiles/llama-cli.dir/main.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-cli\u001b[0m\n",
            "[ 88%] Built target llama-cli\n",
            "[ 88%] \u001b[32mBuilding CXX object tools/perplexity/CMakeFiles/llama-perplexity.dir/perplexity.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-perplexity\u001b[0m\n",
            "[ 89%] Built target llama-perplexity\n",
            "[ 90%] \u001b[32mBuilding CXX object tools/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-quantize\u001b[0m\n",
            "[ 90%] Built target llama-quantize\n",
            "[ 91%] \u001b[34m\u001b[1mGenerating loading.html.hpp\u001b[0m\n",
            "[ 91%] \u001b[34m\u001b[1mGenerating index.html.gz.hpp\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object tools/server/CMakeFiles/llama-server.dir/server.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-server\u001b[0m\n",
            "[ 92%] Built target llama-server\n",
            "[ 92%] \u001b[32mBuilding CXX object tools/run/CMakeFiles/llama-run.dir/run.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object tools/run/CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-run\u001b[0m\n",
            "[ 93%] Built target llama-run\n",
            "[ 93%] \u001b[32mBuilding CXX object tools/tokenize/CMakeFiles/llama-tokenize.dir/tokenize.cpp.o\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-tokenize\u001b[0m\n",
            "[ 94%] Built target llama-tokenize\n",
            "[ 94%] \u001b[32mBuilding CXX object tools/tts/CMakeFiles/llama-tts.dir/tts.cpp.o\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-tts\u001b[0m\n",
            "[ 94%] Built target llama-tts\n",
            "[ 94%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-llava-cli\u001b[0m\n",
            "[ 94%] Built target llama-llava-cli\n",
            "[ 94%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gemma3-cli\u001b[0m\n",
            "[ 95%] Built target llama-gemma3-cli\n",
            "[ 96%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-minicpmv-cli\u001b[0m\n",
            "[ 96%] Built target llama-minicpmv-cli\n",
            "[ 97%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-qwen2vl-cli\u001b[0m\n",
            "[ 97%] Built target llama-qwen2vl-cli\n",
            "[ 98%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-mtmd-cli\u001b[0m\n",
            "[ 98%] Built target llama-mtmd-cli\n",
            "[ 98%] \u001b[32mBuilding CXX object tools/cvector-generator/CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o\u001b[0m\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-cvector-generator\u001b[0m\n",
            "[ 99%] Built target llama-cvector-generator\n",
            "[100%] \u001b[32mBuilding CXX object tools/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-export-lora\u001b[0m\n",
            "[100%] Built target llama-export-lora\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models\n",
        "!wget https://huggingface.co/TheBloke/TinyLLaMA-1.1B-Chat-v0.3-GGUF/resolve/main/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q-1apNlz-8aG",
        "outputId": "e4cbf9ad-d184-46c5-d7ab-f4d7c884882b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models\n",
            "--2025-07-28 03:25:55--  https://huggingface.co/TheBloke/TinyLLaMA-1.1B-Chat-v0.3-GGUF/resolve/main/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.124, 18.172.134.88, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF/resolve/main/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf [following]\n",
            "--2025-07-28 03:25:55--  https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF/resolve/main/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/65/bb/65bb2b45ed3e7c59378b71dc526f1f5a568b37d1354b0f80871ac18c114af42b/2d3bd82534bb6c6e0f4be1761b29b25bdcd65855a022513cb65f24ad3b25e41f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf%3B+filename%3D%22tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf%22%3B&Expires=1753676755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MzY3Njc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82NS9iYi82NWJiMmI0NWVkM2U3YzU5Mzc4YjcxZGM1MjZmMWY1YTU2OGIzN2QxMzU0YjBmODA4NzFhYzE4YzExNGFmNDJiLzJkM2JkODI1MzRiYjZjNmUwZjRiZTE3NjFiMjliMjViZGNkNjU4NTVhMDIyNTEzY2I2NWYyNGFkM2IyNWU0MWY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=V4A7LHWRwy86QHl8TILhvb8DS5X49hWCc7ARcy8Ie180pksThh8OKe4GpmDcCTb8jjGKtXZOzmmsmKMdfW5gQncABk6oYxJs1MyuO4hi43js4wTfNHwLddirzI-KRTOfyVu0bD-ZszPR3TESXhYuUosBVKMiz02atiwShAnAuJkrsLjrdpgjTY7J6nsDv34FZ%7EzvoEX3LHaGDtuWqtkuLS1Y5OQf2XgIbSkdS8zSbPZyPs%7EObu3Px-miOkURkmpMmulRH5eJL4yv8ZNjVojmp2w56D4Rny5DRaxtlvhIU-8rcFaGyn6sIrAKBrlXr3QSdcoywo6SWturIOqSe6aDFg__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-07-28 03:25:55--  https://cdn-lfs.hf.co/repos/65/bb/65bb2b45ed3e7c59378b71dc526f1f5a568b37d1354b0f80871ac18c114af42b/2d3bd82534bb6c6e0f4be1761b29b25bdcd65855a022513cb65f24ad3b25e41f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf%3B+filename%3D%22tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf%22%3B&Expires=1753676755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MzY3Njc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82NS9iYi82NWJiMmI0NWVkM2U3YzU5Mzc4YjcxZGM1MjZmMWY1YTU2OGIzN2QxMzU0YjBmODA4NzFhYzE4YzExNGFmNDJiLzJkM2JkODI1MzRiYjZjNmUwZjRiZTE3NjFiMjliMjViZGNkNjU4NTVhMDIyNTEzY2I2NWYyNGFkM2IyNWU0MWY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=V4A7LHWRwy86QHl8TILhvb8DS5X49hWCc7ARcy8Ie180pksThh8OKe4GpmDcCTb8jjGKtXZOzmmsmKMdfW5gQncABk6oYxJs1MyuO4hi43js4wTfNHwLddirzI-KRTOfyVu0bD-ZszPR3TESXhYuUosBVKMiz02atiwShAnAuJkrsLjrdpgjTY7J6nsDv34FZ%7EzvoEX3LHaGDtuWqtkuLS1Y5OQf2XgIbSkdS8zSbPZyPs%7EObu3Px-miOkURkmpMmulRH5eJL4yv8ZNjVojmp2w56D4Rny5DRaxtlvhIU-8rcFaGyn6sIrAKBrlXr3QSdcoywo6SWturIOqSe6aDFg__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.167.152.106, 3.167.152.37, 3.167.152.12, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.167.152.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 667822976 (637M) [binary/octet-stream]\n",
            "Saving to: ‘tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf’\n",
            "\n",
            "tinyllama-1.1b-chat 100%[===================>] 636.88M   346MB/s    in 1.8s    \n",
            "\n",
            "2025-07-28 03:25:57 (346 MB/s) - ‘tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf’ saved [667822976/667822976]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fusermount -u /content/drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ssU3nGFvPRp0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "a6e010b7-2502-4306-db29-8e48a0477cd9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusermount: failed to unmount /content/drive: Invalid argument\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must not already contain files",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-2858189708.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fusermount -u /content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os, json\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# List of your uploaded CSV filenames\n",
        "csv_files = [\"/content/drive/MyDrive/Ncert_dataset/NCERT_Dataset.csv\"]\n",
        "\n",
        "os.makedirs(\"embeddings\", exist_ok=True)\n",
        "os.makedirs(\"texts\", exist_ok=True)\n",
        "\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(file)\n",
        "    combined_texts = (df[\"Question\"] + \" \" + df[\"Answer\"]).tolist()\n",
        "\n",
        "    # Get filename only (no directory or extension)\n",
        "    base_name = Path(file).stem  # \"NCERT_Dataset\"\n",
        "\n",
        "    # Save original data for later retrieval\n",
        "    with open(f'texts/{base_name}.json', 'w') as f:\n",
        "        json.dump(combined_texts, f)\n",
        "\n",
        "    # Embed and index\n",
        "    embeddings = model.encode(combined_texts, show_progress_bar=True).astype(\"float32\")\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    index.add(embeddings)\n",
        "\n",
        "    # Save the FAISS index\n",
        "    faiss.write_index(index, f'embeddings/{base_name}.index')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "cssIItb1GGww",
        "outputId": "1856cf36-1dde-4d2c-d5be-ff8dd6926a43",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'faiss'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1330752499.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faiss'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_search(query, base_name=\"NCERT_Dataset\", top_k=5):\n",
        "    # Load FAISS index\n",
        "    index = faiss.read_index(f'embeddings/{base_name}.index')\n",
        "\n",
        "    # Load original text list\n",
        "    with open(f'texts/{base_name}.json', 'r') as f:\n",
        "        texts = json.load(f)\n",
        "\n",
        "    # Embed the query\n",
        "    query_vector = model.encode([query]).astype(\"float32\")\n",
        "\n",
        "    # Search the index\n",
        "    distances, indices = index.search(query_vector, top_k)\n",
        "\n",
        "    # Return top matches\n",
        "    results = [texts[i] for i in indices[0]]\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "7_r9QRSYOofb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = semantic_search(input(), top_k=3)\n",
        "for i, res in enumerate(results, 1):\n",
        "    print(f\"\\n🔹 Result {i}:\\n{res}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HXsrN5B8OowV",
        "outputId": "cb694875-7117-41df-cc2c-7a01ae99533a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is democracy\n",
            "\n",
            "🔹 Result 1:\n",
            "What is democracy? Democracy is a form of government where citizens have the power to make decisions, either directly or through elected representatives.\n",
            "\n",
            "🔹 Result 2:\n",
            "What is democracy? Democracy is a form of government where citizens have the power to participate in decision-making processes, often through elected representatives.\n",
            "\n",
            "🔹 Result 3:\n",
            "What is democracy? Democracy is a form of government in which the rulers are elected by the people.\n",
            "\n",
            "🔹 Result 4:\n",
            "What is democracy? Democracy is a form of government where power is vested in the people, who exercise this power through elected representatives. It emphasizes equality, freedom, and the rule of law.\n",
            "\n",
            "🔹 Result 5:\n",
            "What is democracy? Democracy is a system of governance where power is vested in the people, who rule either directly or through freely elected representatives.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def extract_answer_format(query):\n",
        "    if \"1-mark\" in query or \"1 mark\" in query:\n",
        "        return \"1-mark\"\n",
        "    elif \"2-mark\" in query or \"2 mark\" in query:\n",
        "        return \"2-mark\"\n",
        "    elif \"5-mark\" in query or \"5 mark\" in query:\n",
        "        return \"5-mark\"\n",
        "    return \"short\"\n",
        "\n",
        "def run_rag_query(query):\n",
        "    corrected_query = correct_spelling(query)\n",
        "    print(f\"🔎 Corrected Query: {corrected_query}\")\n",
        "\n",
        "    answer_format = extract_answer_format(corrected_query)\n",
        "\n",
        "    # Then embed and retrieve using corrected_query instead of original query\n",
        "\n",
        "def run_rag_query(corrected_query, base_name=\"NCERT_Dataset\", top_k=5, model_path=\"./models/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf\", max_tokens=200):\n",
        "    # Step 1: Semantic Search\n",
        "    results = semantic_search(query, base_name=base_name, top_k=top_k)\n",
        "\n",
        "    # Step 2: Create RAG Prompt\n",
        "    context = \"\\n\\n\".join(results)\n",
        "    prompt = f\"\"\"You are a helpful AI tutor for NCERT students.\n",
        "\n",
        "Answer the following question **in a [1-mark/2-mark/3-mark/4-mark/5-mark] format** with accurate, grade-appropriate explanation.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "Answer:\"\"\"\n",
        "\n",
        "    # Step 3: Save prompt to file\n",
        "    with open(\"prompt.txt\", \"w\") as f:\n",
        "        f.write(prompt)\n",
        "\n",
        "    # Step 4: Call llama.cpp via subprocess\n",
        "    cmd = [\n",
        "        \"./build/bin/llama-cli\",\n",
        "        \"-m\", model_path,\n",
        "        \"-f\", \"prompt.txt\",         # read prompt from file\n",
        "        \"--color\",\n",
        "        \"-n\", str(max_tokens),\n",
        "    ]\n",
        "\n",
        "    print(\"🔁 Running TinyLLaMA for generation...\")\n",
        "    output = subprocess.check_output(cmd, universal_newlines=True)\n",
        "    return output"
      ],
      "metadata": {
        "id": "Rwt1WELUPDUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/wolfgarbe/SymSpell/master/SymSpell/frequency_dictionary_en_82_765.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfYRoX2ZUJkh",
        "outputId": "49e3e087-e91e-4c62-ce1c-1b271b5cb116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-26 05:59:42--  https://raw.githubusercontent.com/wolfgarbe/SymSpell/master/SymSpell/frequency_dictionary_en_82_765.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1332881 (1.3M) [text/plain]\n",
            "Saving to: ‘frequency_dictionary_en_82_765.txt’\n",
            "\n",
            "frequency_dictionar 100%[===================>]   1.27M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-07-26 05:59:43 (29.5 MB/s) - ‘frequency_dictionary_en_82_765.txt’ saved [1332881/1332881]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from symspellpy.symspellpy import SymSpell, Verbosity\n",
        "\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "\n",
        "dictionary_path = \"frequency_dictionary_en_82_765.txt\"\n",
        "term_index = 0  # column of the term in dictionary text file\n",
        "count_index = 1  # column of the term frequency\n",
        "\n",
        "if not sym_spell.load_dictionary(dictionary_path, term_index, count_index):\n",
        "    raise FileNotFoundError(f\"Dictionary file not found at {dictionary_path}\")\n",
        "\n",
        "def correct_spelling(query):\n",
        "    suggestions = sym_spell.lookup_compound(query, max_edit_distance=2)\n",
        "    return suggestions[0].term if suggestions else query\n"
      ],
      "metadata": {
        "id": "kggx8r3MT8CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- IMPORTS ---\n",
        "from symspellpy.symspellpy import SymSpell, Verbosity\n",
        "import language_tool_python\n",
        "import subprocess\n",
        "\n",
        "# --- SETUP SPELL CHECKER ---\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "dictionary_path = \"frequency_dictionary_en_82_765.txt\"\n",
        "if not sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1):\n",
        "    raise FileNotFoundError(f\"Dictionary file not found at {dictionary_path}\")\n",
        "\n",
        "# --- SETUP GRAMMAR TOOL ---\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "\n",
        "# --- SPELL + GRAMMAR CORRECTION FUNCTION ---\n",
        "def correct_spelling_and_grammar(text):\n",
        "    suggestions = sym_spell.lookup_compound(text, max_edit_distance=2)\n",
        "    corrected = suggestions[0].term if suggestions else text\n",
        "    corrected_text = tool.correct(corrected)\n",
        "    return corrected_text\n",
        "\n",
        "# --- ANSWER FORMAT EXTRACTOR ---\n",
        "def extract_answer_format(query):\n",
        "    query = query.lower()\n",
        "    if \"1-mark\" in query or \"1 mark\" in query:\n",
        "        return \"1-mark\"\n",
        "    elif \"2-mark\" in query or \"2 mark\" in query:\n",
        "        return \"2-mark\"\n",
        "    elif \"5-mark\" in query or \"5 mark\" in query:\n",
        "        return \"5-mark\"\n",
        "    return \"short\"\n",
        "\n",
        "# --- MAIN RAG QUERY FUNCTION ---\n",
        "def run_rag_query(query, base_name=\"NCERT_Dataset\", top_k=5, model_path=\"./models/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf\", max_tokens=200):\n",
        "    # Step 1: Spell + Grammar Correction\n",
        "    corrected_query = correct_spelling_and_grammar(query)\n",
        "    print(f\"🔎 Corrected Query: {corrected_query}\")\n",
        "\n",
        "    # Step 2: Extract Answer Format\n",
        "    answer_format = extract_answer_format(corrected_query)\n",
        "\n",
        "    # Step 3: Perform Semantic Search\n",
        "    results = semantic_search(corrected_query, base_name=base_name, top_k=top_k)\n",
        "    context = \"\\n\\n\".join(results)\n",
        "\n",
        "    # Step 4: Construct Prompt\n",
        "    prompt = f\"\"\"Use the following NCERT context to answer the question in a {answer_format} format for a student of class 9.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {corrected_query}\n",
        "Answer:\"\"\"\n",
        "\n",
        "    # Step 5: Save Prompt & Generate Response\n",
        "    with open(\"prompt.txt\", \"w\") as f:\n",
        "        f.write(prompt)\n",
        "\n",
        "    cmd = [\n",
        "        \"./build/bin/llama-cli\",\n",
        "        \"-m\", model_path,\n",
        "        \"-f\", \"prompt.txt\",\n",
        "        \"--color\",\n",
        "        \"-n\", str(max_tokens),\n",
        "    ]\n",
        "\n",
        "    print(\"🔁 Running TinyLLaMA for generation...\")\n",
        "    output = subprocess.check_output(cmd, universal_newlines=True)\n",
        "    return output\n",
        "\n",
        "# --- EXAMPLE USAGE ---\n",
        "query = input(\"💬 Ask your question: \")\n",
        "output = run_rag_query(query)\n",
        "print(\"📚 Final Answer:\\n\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V6WIM4HQSd6w",
        "outputId": "a0f45f80-4e0d-4c2c-b6b2-a626f6a8da8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💬 Ask your question: what mitochondira\n",
            "🔎 Corrected Query: What mitochondria\n",
            "🔁 Running TinyLLaMA for generation...\n",
            "📚 Final Answer:\n",
            " \u001b[33m\u001b[0m Use the following NCERT context to answer the question in a short format for a student of class 9.\n",
            "\n",
            "Context:\n",
            "Describe the role of mitochondria in a cell. Mitochondria are responsible for producing energy in the form of ATP through the process of cellular respiration. They are often referred to as the powerhouses of the cell.\n",
            "\n",
            "Describe the role of mitochondria in the process of cellular respiration. Mitochondria are the powerhouses of the cell where the process of cellular respiration occurs. They convert glucose into ATP through a series of reactions, including glycolysis, the Krebs cycle, and the electron transport chain, which requires oxygen.\n",
            "\n",
            "Describe the structure of mitochondria and explain why they are considered unique organelles. Mitochondria have a double membrane structure with an outer and inner membrane. The inner membrane is folded into cristae, which increase the surface area for chemical reactions. Mitochondria are unique because they contain their own DNA and ribosomes, allowing them to synthesize some of their own proteins independently of the cell's nucleus.\n",
            "\n",
            "Provide an example of a cell organelle and describe its function. An example of a cell organelle is the mitochondrion. Mitochondria are often referred to as the \"powerhouses of the cell\" because they generate most of the cell's supply of adenosine triphosphate (ATP), used as a source of chemical energy. Mitochondria are involved in cellular respiration, which includes processes like the Krebs cycle and oxidative phosphorylation.\n",
            "\n",
            "Describe the structure of a mitochondrion, including its membranes and the matrix. A mitochondrion has an outer membrane and an inner membrane. The inner membrane is folded into structures called cristae, which increase the surface area for chemical reactions. The space within the inner membrane is called the matrix, which contains circular DNA, RNA molecules, ribosomes, and components required for protein synthesis.\n",
            "\n",
            "Question: What mitochondria\n",
            "Answer: The mitochondria are the powerhouses of the cell. They are often referred to as the powerhouses of the cell. They convert glucose into ATP through a series of reactions involving glycolysis, the Krebs cycle, and the electron transport chain. This process is necessary for cellular respiration. They also synthesize their own DNA and ribosomes, allowing them to synthesize some of their own proteins independently of the cell's nucleus.\n",
            "\n",
            "Question: Why are mitochondria considered unique organelles?\n",
            "Answer: Mitochondria have a double membrane structure with an outer and inner membrane. The inner membrane is folded into cristae, which increase the surface area for chemical reactions. Mitochondria are unique because they contain their own DNA and ribosomes, allowing them to synthesize some of their own proteins independently of the cell's nucleus\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXAMPLE USAGE ---\n",
        "query = input(\"💬 Ask your question: \")\n",
        "output = run_rag_query(query)\n",
        "print(\"📚 Final Answer:\\n\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F9Cnk3qXTOI",
        "outputId": "3526bbca-1579-433b-e012-2c62aabfbf87",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💬 Ask your question: kabilesh\n",
            "🔎 Corrected Query: Key flesh\n",
            "🔁 Running TinyLLaMA for generation...\n",
            "📚 Final Answer:\n",
            " \u001b[33m\u001b[0m Use the following NCERT context to answer the question in a short format for a student of class 9.\n",
            "\n",
            "Context:\n",
            "Describe the difference between fleshy and dry fruits, providing one example of each. Fleshy fruits have a soft, edible pericarp, such as in mangoes, while dry fruits have a hard, inedible pericarp, like in groundnuts.\n",
            "\n",
            "What is the primary material used to make cylinder seals? Stone\n",
            "\n",
            "What material was commonly used to make Harappan seals? Steatite\n",
            "\n",
            "What is typically found on Harappan seals? A line of writing and a motif, usually an animal.\n",
            "\n",
            "Identify the type of tissue in the following: skin. Epithelial tissue\n",
            "\n",
            "Question: Key flesh\n",
            "Answer: Stone\n",
            "\n",
            "Question: Key material Steatite\n",
            "Answer: Stone\n",
            "\n",
            "Question: Key material type Steatite\n",
            "Answer: Steatite\n",
            "\n",
            "Question: Key type material Steatite\n",
            "Answer: Steatite\n",
            "\n",
            "Question: Primary material Steatite\n",
            "Answer: Steatite\n",
            "\n",
            "Question: Typical material Steatite\n",
            "Answer: Steatite\n",
            "\n",
            "Question: Epithelial tissue\n",
            "Answer: Lipid\n",
            "\n",
            "Question: Skin\n",
            "Answer: Epithelial tissue\n",
            "\n",
            "Question: Epithelial tissue\n",
            "Answer: Lipid\n",
            "\n",
            "Question: Skin\n",
            "Answer: Lipid\n",
            "\n",
            "Question: Epithelial tissue\n",
            "Answer: Lipid\n",
            "\n",
            "Question: Skin\n",
            "Answer: Lipid\n",
            "\n",
            "Question: Epithelial tissue\n",
            "Answer: Lipid\n",
            "\n",
            "Question: Skin\n",
            "Answer: Lipid\n",
            "\n",
            "Question: Epithelial tissue\n",
            "Answer: Lipid\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install language-tool-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "719UIkBpYuL6",
        "outputId": "82d284fa-d887-4d1c-9f44-45bede76762d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting language-tool-python\n",
            "  Downloading language_tool_python-2.9.4-py3-none-any.whl.metadata (55 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (5.9.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2025.7.14)\n",
            "Downloading language_tool_python-2.9.4-py3-none-any.whl (55 kB)\n",
            "Installing collected packages: language-tool-python\n",
            "Successfully installed language-tool-python-2.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrade Java to 17+\n",
        "!sudo apt update\n",
        "!sudo apt install openjdk-17-jdk -y\n",
        "\n",
        "# Set JAVA_HOME to Java 17\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
        "\n",
        "# Confirm version (optional)\n",
        "!java -version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4XwfmYW0ZUo5",
        "outputId": "be480a6c-8e93-4e4f-f4cd-6b75241d7203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Connecting to security.ub\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Connecting to security.ub\u001b[0m\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [\u001b[0m\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\u001b[0m\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\u001b[33m\r0% [4 InRelease 12.7 kB/128 kB 10%] [Waiting for headers] [Waiting for headers]\u001b[0m\u001b[33m\r0% [4 InRelease 15.6 kB/128 kB 12%] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,853 kB]\n",
            "\u001b[33m\r0% [4 InRelease 15.6 kB/128 kB 12%] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                               \rGet:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,768 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,574 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,471 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,160 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,142 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,269 kB]\n",
            "Fetched 23.6 MB in 2s (10.5 MB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxt-dev libxtst6 libxxf86dga1\n",
            "  openjdk-17-jdk-headless openjdk-17-jre openjdk-17-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  libxt-doc openjdk-17-demo openjdk-17-source visualvm libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  | fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxt-dev libxtst6 libxxf86dga1 openjdk-17-jdk\n",
            "  openjdk-17-jdk-headless openjdk-17-jre openjdk-17-jre-headless x11-utils\n",
            "0 upgraded, 12 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 126 MB of archives.\n",
            "After this operation, 288 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre-headless amd64 17.0.15+6~us1-0ubuntu1~22.04 [48.3 MB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre amd64 17.0.15+6~us1-0ubuntu1~22.04 [232 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk-headless amd64 17.0.15+6~us1-0ubuntu1~22.04 [71.3 MB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk amd64 17.0.15+6~us1-0ubuntu1~22.04 [2,403 kB]\n",
            "Fetched 126 MB in 6s (20.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 12.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../01-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../02-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../03-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../04-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../05-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../06-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../07-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-17-jre-headless:amd64.\n",
            "Preparing to unpack .../08-openjdk-17-jre-headless_17.0.15+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jre-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-17-jre:amd64.\n",
            "Preparing to unpack .../09-openjdk-17-jre_17.0.15+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jre:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-17-jdk-headless:amd64.\n",
            "Preparing to unpack .../10-openjdk-17-jdk-headless_17.0.15+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
            "Preparing to unpack .../11-openjdk-17-jdk_17.0.15+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up openjdk-17-jre-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up openjdk-17-jre:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up openjdk-17-jdk-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "Setting up openjdk-17-jdk:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "openjdk version \"17.0.15\" 2025-04-15\n",
            "OpenJDK Runtime Environment (build 17.0.15+6-Ubuntu-0ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.15+6-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from symspellpy.symspellpy import SymSpell, Verbosity\n",
        "import language_tool_python\n",
        "\n",
        "# Load spell checker\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2)\n",
        "sym_spell.load_dictionary(\"frequency_dictionary_en_82_765.txt\", term_index=0, count_index=1)\n",
        "\n",
        "# Load grammar tool\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "\n",
        "def correct_spelling_and_grammar(text):\n",
        "    # Spell correction\n",
        "    suggestions = sym_spell.lookup_compound(text, max_edit_distance=2)\n",
        "    corrected = suggestions[0].term if suggestions else text\n",
        "\n",
        "    # Grammar correction\n",
        "    corrected_text = tool.correct(corrected)\n",
        "\n",
        "    return corrected_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHJKiKPXYwEb",
        "outputId": "56b0dbf2-cc90-4113-ca6c-235bf7848088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading LanguageTool latest: 100%|██████████| 252M/252M [00:15<00:00, 16.6MB/s]\n",
            "INFO:language_tool_python.download_lt:Unzipping /tmp/tmpzh8a8iel.zip to /root/.cache/language_tool_python.\n",
            "INFO:language_tool_python.download_lt:Downloaded https://internal1.languagetool.org/snapshots/LanguageTool-latest-snapshot.zip to /root/.cache/language_tool_python.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"embeddings\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XLP0-033S_Tw",
        "outputId": "cca52809-4b9d-49f4-d129-1d40d7abe31d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NCERT_Dataset.index']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = run_rag_query(\"What is the law of conservation of mass?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CZWhpG5FTA6I",
        "outputId": "4c1af4ab-9200-45c6-b970-1b57e02c22be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔁 Running TinyLLaMA for generation...\n",
            "\u001b[33m\u001b[0m Use the following NCERT context to answer the question clearly and concisely for a student of class 9.\n",
            "\n",
            "Context:\n",
            "What is the law of conservation of mass? The law of conservation of mass states that mass cannot be created or destroyed in a chemical reaction; it can only change form.\n",
            "\n",
            "Describe the Law of Conservation of Mass in your own words. The Law of Conservation of Mass states that the total mass of the substances involved in a chemical reaction remains constant; it is neither created nor destroyed, but merely changes form.\n",
            "\n",
            "State the Law of Conservation of Mass. The Law of Conservation of Mass states that mass can neither be created nor destroyed in a chemical reaction.\n",
            "\n",
            "Describe the Law of Conservation of Mass in your own words. The Law of Conservation of Mass states that the total mass of the substances that react in a chemical reaction is equal to the total mass of the substances produced by the reaction. This means that mass is neither created nor destroyed during a chemical reaction.\n",
            "\n",
            "What is the law of conservation of mass? The law of conservation of mass states that mass cannot be created nor destroyed in a chemical reaction.\n",
            "\n",
            "Question: What is the law of conservation of mass?\n",
            "Answer: The law of conservation of mass states that mass cannot be created nor destroyed in a chemical reaction. It is a fundamental law of nature that the total mass of a substance involved in a chemical reaction remains constant. It states that the mass of the substance produced during a chemical reaction is the same as the mass of the substance that reacted. This means that mass can neither be created nor destroyed during a chemical reaction. The law of conservation of mass is important in understanding the working of chemical reactions and how they produce the products.\n",
            "\n",
            "Describe the law of conservation of mass in your own words. The Law of Conservation of Mass states that the total mass of the substances involved in a chemical reaction remains constant; it is neither created nor destroyed, but merely changes form. The law of conservation of mass is important in understanding the working of chemical reactions and how they produce the products. It helps to explain the principles of chemical reaction and how mass is conserved during a chemical\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U openai-whisper coqui-tts soundfile"
      ],
      "metadata": {
        "id": "ev4D_-vpmZgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " B. Convert user voice to query text"
      ],
      "metadata": {
        "id": "UiA67GowmlCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result[\"text\"]\n",
        "import sounddevice as sd\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "def record_voice(filename=\"input.wav\", duration=5, fs=16000):\n",
        "    print(\"🎙️ Recording...\")\n",
        "    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
        "    sd.wait()\n",
        "    write(filename, fs, audio)\n",
        "    print(\"✅ Done recording.\")\n",
        "    return filename"
      ],
      "metadata": {
        "id": "xF7D0R7pmh6_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}